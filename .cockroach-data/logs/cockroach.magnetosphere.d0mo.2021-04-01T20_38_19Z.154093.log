I210401 20:38:19.585202 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2021/04/01 20:38:19
I210401 20:38:19.585210 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹magnetosphere›
I210401 20:38:19.585215 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.0 (x86_64-unknown-linux-gnu, built 2020/11/09 16:01:45, go1.13.14)
I210401 20:38:19.585221 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[cockroach start --certs-dir=certs --advertise-addr=192.168.2.118 --join=192.168.2.130 --cache=.25 --max-sql-memory=.25]›
I210401 20:38:19.585230 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
I210401 20:38:19.585104 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups is unsupported, using system memory 16 GiB instead: can't read available memory from cgroup v2 at /sys/fs/cgroup/unified/user.slice/user-1000.slice/session-29.scope/memory.max: open /sys/fs/cgroup/unified/user.slice/user-1000.slice/session-29.scope/memory.max: no such file or directory›
I210401 20:38:19.585305 1 cli/start.go:1163 ⋮ ‹CockroachDB CCL v20.2.0 (x86_64-unknown-linux-gnu, built 2020/11/09 16:01:45, go1.13.14)›
I210401 20:38:19.585835 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups is unsupported, using system memory 16 GiB instead: can't read available memory from cgroup v2 at /sys/fs/cgroup/unified/user.slice/user-1000.slice/session-29.scope/memory.max: open /sys/fs/cgroup/unified/user.slice/user-1000.slice/session-29.scope/memory.max: no such file or directory›
I210401 20:38:19.585850 1 server/config.go:433 ⋮ system total memory: ‹16 GiB›
I210401 20:38:19.585865 1 server/config.go:435 ⋮ server configuration:
‹max offset             500000000›
‹cache size             3.9 GiB›
‹SQL memory pool size   3.9 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I210401 20:38:19.585908 1 cli/start.go:967 ⋮ process identity: ‹uid 1000 euid 1000 gid 1000 egid 1000›
I210401 20:38:19.586056 1 cli/start.go:501 ⋮ could not initialize GEOS - spatial functions may not be available: geos: error during GEOS init: geos: cannot load GEOS from dir ‹"/usr/local/lib/cockroach"›: ‹geos error: /usr/local/lib/cockroach/libgeos.so: cannot open shared object file: No such file or directory›
I210401 20:38:19.586090 1 cli/start.go:508 ⋮ starting cockroach node
I210401 20:38:19.587136 72 rpc/tls.go:270 ⋮ [n?] server certificate addresses: ‹IP=127.0.0.1,192.168.2.118; DNS=localhost,magnetosphere,magnetosphere.net; CN=node›
I210401 20:38:19.587176 72 rpc/tls.go:319 ⋮ [n?] web UI certificate addresses: ‹IP=127.0.0.1,192.168.2.118; DNS=localhost,magnetosphere,magnetosphere.net; CN=node›
I210401 20:38:19.612244 72 server/server.go:781 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I210401 20:38:19.627807 72 server/config.go:624 ⋮ [n?] 1 storage engine‹› initialized
I210401 20:38:19.627842 72 server/config.go:627 ⋮ [n?] ‹Pebble cache size: 3.9 GiB›
I210401 20:38:19.627853 72 server/config.go:627 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 10000›
I210401 20:38:19.630945 72 util/log/log.go:50 ⋮ initial startup completed
Node will now attempt to join a running cluster, or wait for `cockroach init`.
Client connections will be accepted after this completes successfully.
Check the log file(s) for progress. 
I210401 20:38:19.637479 72 server/init.go:208 ⋮ [n?] no stores bootstrapped
I210401 20:38:19.637506 72 server/init.go:209 ⋮ [n?] awaiting `cockroach init` or join with an already initialized node
W210401 20:38:19.637858 187 vendor/google.golang.org/grpc/internal/channelz/logging.go:73 ⋮ ‹grpc: addrConn.createTransport failed to connect to {192.168.2.130:26257  <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused". Reconnecting...›
W210401 20:38:19.637934 185 server/init.go:436 ⋮ [n?] outgoing join rpc to ‹192.168.2.130:26257› unsuccessful: ‹rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused"›
W210401 20:38:20.638732 185 server/init.go:474 ⋮ [n?] outgoing join rpc to ‹192.168.2.130:26257› unsuccessful: ‹rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused"›
W210401 20:38:21.638511 185 server/init.go:474 ⋮ [n?] outgoing join rpc to ‹192.168.2.130:26257› unsuccessful: ‹rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused"›
W210401 20:38:22.638830 185 server/init.go:474 ⋮ [n?] outgoing join rpc to ‹192.168.2.130:26257› unsuccessful: ‹rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused"›
W210401 20:38:23.638541 185 server/init.go:474 ⋮ [n?] outgoing join rpc to ‹192.168.2.130:26257› unsuccessful: ‹rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused"›
W210401 20:38:24.638877 185 server/init.go:474 ⋮ [n?] outgoing join rpc to ‹192.168.2.130:26257› unsuccessful: ‹rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 192.168.2.130:26257: connect: connection refused"›
W210401 20:38:25.650054 185 server/init.go:472 ⋮ [n?] ‹192.168.2.130:26257› is itself waiting for init, will retry
W210401 20:38:26.653623 185 server/init.go:472 ⋮ [n?] ‹192.168.2.130:26257› is itself waiting for init, will retry
W210401 20:38:27.650172 185 server/init.go:472 ⋮ [n?] ‹192.168.2.130:26257› is itself waiting for init, will retry
W210401 20:38:28.653868 185 server/init.go:472 ⋮ [n?] ‹192.168.2.130:26257› is itself waiting for init, will retry
I210401 20:38:29.546075 72 server/init.go:266 ⋮ [n?] cluster ‹90546476-8089-48e5-80b3-e1e5c2e1c6d0› has been created
I210401 20:38:29.546125 72 server/init.go:267 ⋮ [n?] allocated node ID: n1 (for self)
W210401 20:38:29.546207 72 gossip/gossip.go:1494 ⋮ [n?] no incoming or outgoing connections
I210401 20:38:29.546306 263 server/server.go:1411 ⋮ [n1] connecting to gossip network to verify cluster ID ‹"90546476-8089-48e5-80b3-e1e5c2e1c6d0"›
I210401 20:38:29.546231 72 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"192.168.2.118:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.0" started_at:1617309509546226088 cluster_name:"" sql_address:<network_field:"tcp" address_field:"192.168.2.118:26257" >›
W210401 20:38:29.553971 357 kv/kvserver/store.go:1704 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210401 20:38:29.554066 263 server/server.go:1414 ⋮ [n1] node connected via gossip
I210401 20:38:29.554138 72 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=109 GiB, available=59 GiB, used=44 KiB, logicalBytes=19 KiB), ranges=35, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=166.00 pMax=16616.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I210401 20:38:29.554329 72 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
I210401 20:38:29.559423 72 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I210401 20:38:29.559491 72 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
I210401 20:38:29.559621 72 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/home/d0mo/go/src/github.com/0pcom/magnets/cockroach-data/logs/goroutine_dump›
I210401 20:38:29.559685 72 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/home/d0mo/go/src/github.com/0pcom/magnets/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I210401 20:38:29.559721 72 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I210401 20:38:29.559739 72 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/home/d0mo/go/src/github.com/0pcom/magnets/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I210401 20:38:29.559780 72 server/server.go:1530 ⋮ [n1] starting https server at ‹[::]:8080› (use: ‹192.168.2.118:8080›)
I210401 20:38:29.559813 72 server/server.go:1537 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I210401 20:38:29.559850 72 server/server.go:1538 ⋮ [n1] advertising CockroachDB node at ‹192.168.2.118:26257›
F210401 20:38:29.561247 276 server/server.go:275 ⋮ [n1] clock synchronization error: this node is more than 500ms away from at least half of the known nodes (0 of 1 are within the offset)
goroutine 276 [running]:
github.com/cockroachdb/cockroach/pkg/util/log.getStacks(0x95d8e00, 0x78eac6, 0xc0019ab3a8, 0x78eac6)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/log/get_stacks.go:25 +0xb8
github.com/cockroachdb/cockroach/pkg/util/log.(*loggerT).outputLogEntry(0x95d7fc0, 0x4, 0x1671d66e1942660d, 0x114, 0x87a10b5, 0x10, 0x113, 0xc00019f0e0, 0x83, 0xc001856388, ...)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/log/clog.go:241 +0xa02
github.com/cockroachdb/cockroach/pkg/util/log.addStructured(0x6209340, 0xc000c80600, 0xc000000004, 0x2, 0x5106b9c, 0x2, 0xc0019ab9f0, 0x1, 0x1)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/log/structured.go:52 +0x1ac
github.com/cockroachdb/cockroach/pkg/util/log.logDepth(0x6209340, 0xc000c80600, 0x1, 0x4, 0x5106b9c, 0x2, 0xc0019ab9f0, 0x1, 0x1)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/log/log.go:44 +0x8c
github.com/cockroachdb/cockroach/pkg/util/log.Fatalf(...)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/log/log.go:165
github.com/cockroachdb/cockroach/pkg/server.NewServer.func1()
	/go/src/github.com/cockroachdb/cockroach/pkg/server/server.go:275 +0xd2
github.com/cockroachdb/cockroach/pkg/rpc.(*Context).runHeartbeat.func3(0x6209280, 0xc0009d22c0, 0xd, 0x1)
	/go/src/github.com/cockroachdb/cockroach/pkg/rpc/context.go:1202 +0x582
github.com/cockroachdb/cockroach/pkg/util/stop.(*Stopper).RunTaskWithErr(0xc00024d440, 0x6209280, 0xc0009d22c0, 0x5125022, 0xd, 0xc00103dd68, 0x0, 0x0)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/stop/stopper.go:326 +0x140
github.com/cockroachdb/cockroach/pkg/rpc.(*Context).runHeartbeat(0xc0003a2000, 0xc000e546e0, 0xc0007a9760, 0x13, 0xc0002b3ec0, 0x0, 0x0)
	/go/src/github.com/cockroachdb/cockroach/pkg/rpc/context.go:1132 +0x45a
github.com/cockroachdb/cockroach/pkg/rpc.(*Context).grpcDialNodeInternal.func1.1.1(0x6209340, 0xc0010168a0)
	/go/src/github.com/cockroachdb/cockroach/pkg/rpc/context.go:1058 +0x79
github.com/cockroachdb/cockroach/pkg/util/stop.(*Stopper).RunWorker.func1(0xc000e724a0, 0xc00024d440, 0xc000e547d0)
	/go/src/github.com/cockroachdb/cockroach/pkg/util/stop/stopper.go:222 +0x13d
created by github.com/cockroachdb/cockroach/pkg/util/stop.(*Stopper).RunWorker
	/go/src/github.com/cockroachdb/cockroach/pkg/util/stop/stopper.go:215 +0xa8

For more context, check log files in: /home/d0mo/go/src/github.com/0pcom/magnets/cockroach-data/logs


****************************************************************************

This node experienced a fatal error (printed above), and as a result the
process is terminating.

Fatal errors can occur due to faulty hardware (disks, memory, clocks) or a
problem in CockroachDB. With your help, the support team at Cockroach Labs
will try to determine the root cause, recommend next steps, and we can
improve CockroachDB based on your report.

Please submit a crash report by following the instructions here:

    https://github.com/cockroachdb/cockroach/issues/new/choose

If you would rather not post publicly, please contact us directly at:

    support@cockroachlabs.com

The Cockroach Labs team appreciates your feedback.
